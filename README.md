# ğŸ“Š Telecom X â€“ Parte 2: PredicciÃ³n de CancelaciÃ³n (Churn)

**Autor:** Junior11995  
**Repositorio Parte 2:** https://github.com/Junior11995/Challenge-TelecomX-Parte2-Prediccion

---

## ğŸ“Œ DescripciÃ³n
Este proyecto corresponde a la **Parte 2 del Challenge Telecom X (ONE + Alura LATAM)**.  
El objetivo es **predecir la evasiÃ³n de clientes (churn)** a partir del dataset tratado en la Parte 1, construyendo y evaluando modelos de Machine Learning.

**Resumen del flujo:**
- Carga del dataset tratado (Parte 1).
- PreparaciÃ³n para ML (drop de IDs, encoding, imputaciÃ³n, balanceo).
- AnÃ¡lisis de correlaciÃ³n y selecciÃ³n de variables.
- Entrenamiento de **al menos dos modelos**:
  - RegresiÃ³n LogÃ­stica (con normalizaciÃ³n).
  - Random Forest (sin normalizaciÃ³n).
- EvaluaciÃ³n con mÃ©tricas y conclusiones estratÃ©gicas.

---

## ğŸ¯ Objetivos
1. Preparar y separar datos (train/test con estratificaciÃ³n).  
2. Tratar desbalance de clases (SMOTE).  
3. Entrenar 2+ modelos de clasificaciÃ³n.  
4. Evaluar con **Accuracy, Precision, Recall, F1, ROC-AUC** y **Matriz de ConfusiÃ³n**.  
5. Identificar **variables mÃ¡s influyentes** y proponer acciones de negocio.

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ telecom_clean.csv # Dataset tratado (producido en Parte 1)
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ desaf_o_telecomx_parte2.ipynb # Notebook principal (Colab/Jupyter)
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ pipeline_churn_smote_lr.joblib # Pipeline (prepro + SMOTE + LR)
â”‚ â”œâ”€â”€ pre_bal.joblib # Preprocesador (imputaciÃ³n + OHE + escala)
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ model_results_comparison.csv # Comparativa de mÃ©tricas
â”‚ â”œâ”€â”€ y_test.csv # y_test para reproducibilidad
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸ› ï¸ TecnologÃ­as
- **Python 3.11**
- **Pandas, NumPy** (manipulaciÃ³n)
- **Scikit-learn** (preprocesamiento, modelado, mÃ©tricas)
- **Imbalanced-learn** (SMOTE)
- **Matplotlib, Seaborn** (visualizaciÃ³n)
- **Joblib** (persistencia de pipelines/modelos)
- Entorno: **Google Colab / Jupyter**

---

## ğŸ”§ PreparaciÃ³n de Datos (resumen)
- **EliminaciÃ³n de columnas irrelevantes**: `customerid` y otros IDs.  
- **CodificaciÃ³n categÃ³rica**: `OneHotEncoder(handle_unknown="ignore")`.  
- **ImputaciÃ³n de nulos**:
  - NumÃ©ricas: `SimpleImputer(strategy="median")`
  - CategÃ³ricas: `SimpleImputer(strategy="most_frequent")`
- **EstandarizaciÃ³n**: `StandardScaler()` **solo para modelos sensibles a escala** (p.ej., RegresiÃ³n LogÃ­stica).
- **Balanceo**: `SMOTE` aplicado **solo en train**.

---

## ğŸ” AnÃ¡lisis
- **CorrelaciÃ³n y selecciÃ³n de variables**:
  - Matriz de correlaciÃ³n con el target.
  - **ChiÂ²** (para variables no negativas) y **ANOVA F-test**.
- **AnÃ¡lisis dirigido**:
  - Tiempo de contrato Ã— Churn  
  - Gasto total Ã— Churn  

---

## ğŸ¤– Modelado
- **Modelo 1 (sens. a escala):** RegresiÃ³n LogÃ­stica (pipeline con imputaciÃ³n + OHE + escalado).  
- **Modelo 2 (no sens. a escala):** Random Forest (pipeline con imputaciÃ³n + OHE).  

**EvaluaciÃ³n** en test (sin reamostrar):  
- Accuracy, Precision, Recall, F1, ROC-AUC  
- Matriz de ConfusiÃ³n  
- Curva ROC

---

## ğŸ“ˆ Resultados
- Desbalance inicial aproximado: **~74%** no churn / **~26%** churn.  
- **Random Forest** suele ofrecer mejor **ROC-AUC** y **Recall** para la clase churn vs. LogReg.  
- Variables influyentes tÃ­picas: **tenure**, **monthlycharges/totalcharges**, tipo de **contrato** y **servicios** (internet/soporte/streaming).

*(Sustituye con tus mÃ©tricas reales del notebook.)*

---

## ğŸš€ EjecuciÃ³n
1. Clonar este repo:
   ```bash
   git clone https://github.com/Junior11995/Challenge-TelecomX-Parte2-Prediccion.git
   cd Challenge-TelecomX-Parte2-Prediccion

Instalar dependencias:

pip install -r requirements.txt


Abrir el notebook:

Google Colab: sube notebooks/desaf_o_telecomx_parte2.ipynb

Jupyter: jupyter notebook notebooks/desaf_o_telecomx_parte2.ipynb

ğŸ§  Conclusiones y Recomendaciones

Modelo recomendado: el que logre mayor ROC-AUC y buen Recall en churn (minimiza falsos negativos).

Posibles mejoras:

ValidaciÃ³n cruzada y ajuste de hiperparÃ¡metros (Grid/Randomized Search).

IngenierÃ­a de variables (interacciones y transformaciones).

Monitoreo y reentrenamiento periÃ³dico con datos recientes.

ğŸ‘¤ Autor

Junior11995 (Junior Alexis Valera)
Analista Junior de Machine Learning â€“ Challenge ONE + Alura LATAM

