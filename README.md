# üìä Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)

**Autor:** Junior11995 (Wilfredo Rojas)  
**Notebook (Colab):** _(agrega tu enlace de Colab Parte 2)_  
**Repositorio Parte 2:** https://github.com/Junior11995/Challenge-TelecomX-Parte2-Prediccion

---

## üìå Descripci√≥n
Este proyecto corresponde a la **Parte 2 del Challenge Telecom X (ONE + Alura LATAM)**.  
El objetivo es **predecir la evasi√≥n de clientes (churn)** a partir del dataset tratado en la Parte 1, construyendo y evaluando modelos de Machine Learning.

**Resumen del flujo:**
- Carga del dataset tratado (Parte 1).
- Preparaci√≥n para ML (drop de IDs, encoding, imputaci√≥n, balanceo).
- An√°lisis de correlaci√≥n y selecci√≥n de variables.
- Entrenamiento de **al menos dos modelos**:
  - Regresi√≥n Log√≠stica (con normalizaci√≥n).
  - Random Forest (sin normalizaci√≥n).
- Evaluaci√≥n con m√©tricas y conclusiones estrat√©gicas.

---

## üéØ Objetivos
1. Preparar y separar datos (train/test con estratificaci√≥n).  
2. Tratar desbalance de clases (SMOTE).  
3. Entrenar 2+ modelos de clasificaci√≥n.  
4. Evaluar con **Accuracy, Precision, Recall, F1, ROC-AUC** y **Matriz de Confusi√≥n**.  
5. Identificar **variables m√°s influyentes** y proponer acciones de negocio.

‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ telecom_clean.csv # Dataset tratado (producido en Parte 1)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ ‚îú‚îÄ‚îÄ desaf_o_telecomx_parte2.ipynb # Notebook principal (Colab/Jupyter)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ ‚îú‚îÄ‚îÄ pipeline_churn_smote_lr.joblib # Pipeline (prepro + SMOTE + LR)
‚îÇ ‚îú‚îÄ‚îÄ pre_bal.joblib # Preprocesador (imputaci√≥n + OHE + escala)
‚îÇ
‚îú‚îÄ‚îÄ outputs/
‚îÇ ‚îú‚îÄ‚îÄ model_results_comparison.csv # Comparativa de m√©tricas
‚îÇ ‚îú‚îÄ‚îÄ y_test.csv # y_test para reproducibilidad
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt


> Si usas otra estructura, actualiza las rutas en el notebook.

---

## üõ†Ô∏è Tecnolog√≠as
- **Python 3.11**
- **Pandas, NumPy** (manipulaci√≥n)
- **Scikit-learn** (preprocesamiento, modelado, m√©tricas)
- **Imbalanced-learn** (SMOTE)
- **Matplotlib, Seaborn** (visualizaci√≥n)
- **Joblib** (persistencia de pipelines/modelos)
- Entorno: **Google Colab / Jupyter**

---

## üîß Preparaci√≥n de Datos (resumen)
- **Eliminaci√≥n de columnas irrelevantes**: `customerid` y otros IDs.  
- **Codificaci√≥n categ√≥rica**: `OneHotEncoder(handle_unknown="ignore")`.  
- **Imputaci√≥n de nulos**:
  - Num√©ricas: `SimpleImputer(strategy="median")`
  - Categ√≥ricas: `SimpleImputer(strategy="most_frequent")`
- **Estandarizaci√≥n**: `StandardScaler()` **solo para modelos sensibles a escala** (p.ej., Regresi√≥n Log√≠stica).
- **Balanceo**: `SMOTE` aplicado **solo en train**.

---

## üîç An√°lisis
- **Correlaci√≥n y selecci√≥n de variables**:
  - Matriz de correlaci√≥n con el target.
  - **Chi¬≤** (para variables no negativas) y **ANOVA F-test**.
- **An√°lisis dirigido**:
  - Tiempo de contrato √ó Churn  
  - Gasto total √ó Churn  

---

## ü§ñ Modelado
- **Modelo 1 (sens. a escala):** Regresi√≥n Log√≠stica (pipeline con imputaci√≥n + OHE + escalado).  
- **Modelo 2 (no sens. a escala):** Random Forest (pipeline con imputaci√≥n + OHE).  

**Evaluaci√≥n** en test (sin reamostrar):  
- Accuracy, Precision, Recall, F1, ROC-AUC  
- Matriz de Confusi√≥n  
- Curva ROC

---

## üìà Resultados (ejemplo esperado)
- Desbalance inicial aproximado: **~74%** no churn / **~26%** churn.  
- **Random Forest** suele ofrecer mejor **ROC-AUC** y **Recall** para la clase churn vs. LogReg.  
- Variables influyentes t√≠picas: **tenure**, **monthlycharges/totalcharges**, tipo de **contrato** y **servicios** (internet/soporte/streaming).

*(Sustituye con tus m√©tricas reales del notebook.)*

---

## üöÄ Ejecuci√≥n
1. Clonar este repo:
   ```bash
   git clone https://github.com/Junior11995/Challenge-TelecomX-Parte2-Prediccion.git
   cd Challenge-TelecomX-Parte2-Prediccion

Instalar dependencias:

pip install -r requirements.txt


Abrir el notebook:

Google Colab: sube notebooks/desaf_o_telecomx_parte2.ipynb

Jupyter: jupyter notebook notebooks/desaf_o_telecomx_parte2.ipynb

üß† Conclusiones y Recomendaciones

Modelo recomendado: el que logre mayor ROC-AUC y buen Recall en churn (minimiza falsos negativos).

Posibles mejoras:

Validaci√≥n cruzada y ajuste de hiperpar√°metros (Grid/Randomized Search).

Ingenier√≠a de variables (interacciones y transformaciones).

Monitoreo y reentrenamiento peri√≥dico con datos recientes.

üë§ Autor

Junior11995 (Junior Alexis Valera)
Analista Junior de Machine Learning ‚Äì Challenge ONE + Alura LATAM

---

## üóÇÔ∏è Estructura
